{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ceae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path    \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8d6017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train annotations: 100%|██████████| 14122/14122 [00:05<00:00, 2646.31it/s]\n",
      "Copying train images: 100%|██████████| 14122/14122 [00:13<00:00, 1082.51it/s]\n",
      "Processing splits:  33%|███▎      | 1/3 [00:18<00:37, 18.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing val annotations: 100%|██████████| 3099/3099 [00:01<00:00, 2779.47it/s]\n",
      "Copying val images: 100%|██████████| 3099/3099 [00:02<00:00, 1144.10it/s]\n",
      "Processing splits:  67%|██████▋   | 2/3 [00:22<00:09,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved val annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test annotations: 100%|██████████| 4306/4306 [00:01<00:00, 2670.36it/s]\n",
      "Copying test images: 100%|██████████| 4306/4306 [00:04<00:00, 883.27it/s]\n",
      "Processing splits: 100%|██████████| 3/3 [00:29<00:00,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path    \n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_coco_structure():\n",
    "    # Define paths\n",
    "    base_dir = Path(\"data\")\n",
    "    data_dir = base_dir\n",
    "    \n",
    "    # Create directory structure\n",
    "    dirs = [\n",
    "        data_dir / \"annotations\",\n",
    "        data_dir / \"train\",\n",
    "        data_dir / \"val\",\n",
    "        data_dir / \"test\",\n",
    "    ]\n",
    "    \n",
    "    for dir_path in dirs:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    return data_dir\n",
    "\n",
    "def yolo_to_coco_bbox(yolo_bbox, img_width, img_height):\n",
    "    \"\"\"Convert YOLO bbox to COCO bbox format [x_min, y_min, width, height]\"\"\"\n",
    "    x_center, y_center, width, height = yolo_bbox\n",
    "    \n",
    "    # Convert normalized coordinates to absolute coordinates\n",
    "    x_center = float(x_center) * img_width\n",
    "    y_center = float(y_center) * img_height\n",
    "    width = float(width) * img_width\n",
    "    height = float(height) * img_height\n",
    "    \n",
    "    # Convert from center coordinates to top-left coordinates\n",
    "    x_min = x_center - (width / 2)\n",
    "    y_min = y_center - (height / 2)\n",
    "    \n",
    "    return [x_min, y_min, width, height]\n",
    "\n",
    "def create_coco_annotations_from_yolo(split_dir, split=\"train\"):\n",
    "    coco_format = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": [\n",
    "            {\"id\": 1, \"name\": \"fire\"},\n",
    "            {\"id\": 2, \"name\": \"smoke\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    image_dir = split_dir / \"images\"\n",
    "    label_dir = split_dir / \"labels\"\n",
    "    annotation_id = 1\n",
    "    \n",
    "    # Process each image and its corresponding label file\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    for img_id, img_file in enumerate(tqdm(image_files, desc=f\"Processing {split} annotations\"), 1):\n",
    "        # Get image dimensions\n",
    "        img_path = image_dir / img_file\n",
    "        with Image.open(img_path) as img:\n",
    "            img_width, img_height = img.size\n",
    "        \n",
    "        # Add image info\n",
    "        image_info = {\n",
    "            \"id\": img_id,\n",
    "            \"file_name\": img_file,\n",
    "            \"height\": img_height,\n",
    "            \"width\": img_width\n",
    "        }\n",
    "        coco_format[\"images\"].append(image_info)\n",
    "        \n",
    "        # Process corresponding label file\n",
    "        label_file = label_dir / f\"{os.path.splitext(img_file)[0]}.txt\"\n",
    "        if label_file.exists():\n",
    "            with open(label_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "                    \n",
    "                    # Convert YOLO bbox to COCO bbox\n",
    "                    bbox = yolo_to_coco_bbox([x_center, y_center, width, height], img_width, img_height)\n",
    "                    \n",
    "                    # Create annotation\n",
    "                    annotation = {\n",
    "                        \"id\": annotation_id,\n",
    "                        \"image_id\": img_id,\n",
    "                        \"category_id\": int(class_id) + 1,  # YOLO uses 0-based indices\n",
    "                        \"bbox\": bbox,\n",
    "                        \"area\": bbox[2] * bbox[3],\n",
    "                        \"iscrowd\": 0\n",
    "                    }\n",
    "                    coco_format[\"annotations\"].append(annotation)\n",
    "                    annotation_id += 1\n",
    "    \n",
    "    return coco_format\n",
    "\n",
    "def main():\n",
    "    # Create directory structure\n",
    "    data_dir = create_coco_structure()\n",
    "    \n",
    "    # Source directories\n",
    "    source_base = Path(\"../data\")  # Your current data directory\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "    \n",
    "    for split in tqdm(splits, desc=\"Processing splits\"):\n",
    "        # Create COCO annotations\n",
    "        split_dir = source_base / split\n",
    "        coco_annotations = create_coco_annotations_from_yolo(split_dir, split)\n",
    "        \n",
    "        # Copy images to new structure\n",
    "        source_images = split_dir / \"images\"\n",
    "        target_images = data_dir / split\n",
    "        \n",
    "        # Copy all images\n",
    "        image_files = [f for f in os.listdir(source_images) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        for img_file in tqdm(image_files, desc=f\"Copying {split} images\"):\n",
    "            shutil.copy2(source_images / img_file, target_images / img_file)\n",
    "        \n",
    "        # Save annotations\n",
    "        with open(data_dir / \"annotations\" / f\"instances_{split}.json\", 'w') as f:\n",
    "            json.dump(coco_annotations, f)\n",
    "        print(f\"Saved {split} annotations\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a3cf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing rtmdet_tiny_8xb32-300e_coco...\n",
      "downloading ---------------------------------------- 0.0/54.9 MiB ? eta -:--:--\n",
      "downloading --------------------------------- 0.0/54.9 MiB 1.1 MB/s eta 0:00:53\n",
      "downloading --------------------------------- 0.1/54.9 MiB 1.5 MB/s eta 0:00:40\n",
      "downloading --------------------------------- 0.4/54.9 MiB 3.0 MB/s eta 0:00:19\n",
      "downloading --------------------------------- 0.5/54.9 MiB 3.3 MB/s eta 0:00:18\n",
      "downloading --------------------------------- 0.7/54.9 MiB 3.7 MB/s eta 0:00:16\n",
      "downloading  -------------------------------- 0.9/54.9 MiB 3.6 MB/s eta 0:00:16\n",
      "downloading  -------------------------------- 1.2/54.9 MiB 5.5 MB/s eta 0:00:11\n",
      "downloading  -------------------------------- 1.4/54.9 MiB 5.5 MB/s eta 0:00:11\n",
      "downloading - ------------------------------- 1.7/54.9 MiB 5.4 MB/s eta 0:00:11\n",
      "downloading - ------------------------------- 1.9/54.9 MiB 5.4 MB/s eta 0:00:11\n",
      "downloading - ------------------------------- 2.2/54.9 MiB 5.9 MB/s eta 0:00:10\n",
      "downloading - ------------------------------- 2.6/54.9 MiB 6.5 MB/s eta 0:00:09\n",
      "downloading - ------------------------------- 2.8/54.9 MiB 6.0 MB/s eta 0:00:10\n",
      "downloading - ------------------------------- 3.1/54.9 MiB 7.3 MB/s eta 0:00:08\n",
      "downloading - ------------------------------- 3.3/54.9 MiB 5.9 MB/s eta 0:00:10\n",
      "downloading -- ------------------------------ 3.6/54.9 MiB 6.6 MB/s eta 0:00:09\n",
      "downloading -- ------------------------------ 3.7/54.9 MiB 5.4 MB/s eta 0:00:10\n",
      "downloading -- ------------------------------ 4.1/54.9 MiB 5.4 MB/s eta 0:00:10\n",
      "downloading -- ------------------------------ 4.5/54.9 MiB 6.5 MB/s eta 0:00:09\n",
      "downloading -- ------------------------------ 5.0/54.9 MiB 9.3 MB/s eta 0:00:06\n",
      "downloading --- ----------------------------- 5.4/54.9 MiB 9.4 MB/s eta 0:00:06\n",
      "downloading --- ----------------------------- 5.8/54.9 MiB 9.4 MB/s eta 0:00:06\n",
      "downloading --- ----------------------------- 5.9/54.9 MiB 7.3 MB/s eta 0:00:08\n",
      "downloading --- ----------------------------- 5.9/54.9 MiB 6.6 MB/s eta 0:00:08\n",
      "downloading --- ----------------------------- 6.1/54.9 MiB 4.7 MB/s eta 0:00:11\n",
      "downloading --- ----------------------------- 6.4/54.9 MiB 4.7 MB/s eta 0:00:11\n",
      "downloading --- ----------------------------- 6.4/54.9 MiB 4.7 MB/s eta 0:00:11\n",
      "downloading --- ----------------------------- 6.5/54.9 MiB 3.3 MB/s eta 0:00:16\n",
      "downloading ---- ---------------------------- 6.9/54.9 MiB 3.9 MB/s eta 0:00:14\n",
      "downloading ---- ---------------------------- 7.1/54.9 MiB 5.0 MB/s eta 0:00:10\n",
      "downloading ---- ---------------------------- 7.6/54.9 MiB 8.2 MB/s eta 0:00:07\n",
      "downloading ---- ---------------------------- 8.0/54.9 MiB 9.4 MB/s eta 0:00:06\n",
      "downloading ----- --------------------------- 8.4/54.9 MiB 9.4 MB/s eta 0:00:06\n",
      "downloading ----- --------------------------- 8.8/54.9 MiB 9.4 MB/s eta 0:00:06\n",
      "downloading ----- -------------------------- 9.2/54.9 MiB 10.9 MB/s eta 0:00:05\n",
      "downloading ----- --------------------------- 9.6/54.9 MiB 9.3 MB/s eta 0:00:06\n",
      "downloading ----- --------------------------- 9.8/54.9 MiB 8.2 MB/s eta 0:00:06\n",
      "downloading ----- -------------------------- 10.2/54.9 MiB 7.3 MB/s eta 0:00:07\n",
      "downloading ------ ------------------------- 10.7/54.9 MiB 9.4 MB/s eta 0:00:05\n",
      "downloading ------ ------------------------ 11.1/54.9 MiB 13.1 MB/s eta 0:00:04\n",
      "downloading ------ ------------------------- 11.4/54.9 MiB 9.3 MB/s eta 0:00:05\n",
      "downloading ------ ------------------------- 11.9/54.9 MiB 9.4 MB/s eta 0:00:05\n",
      "downloading ------- ------------------------ 12.2/54.9 MiB 8.2 MB/s eta 0:00:06\n",
      "downloading ------- ------------------------ 12.5/54.9 MiB 8.2 MB/s eta 0:00:06\n",
      "downloading ------- ------------------------ 13.0/54.9 MiB 8.2 MB/s eta 0:00:06\n",
      "downloading ------- ------------------------ 13.2/54.9 MiB 7.3 MB/s eta 0:00:07\n",
      "downloading ------- ------------------------ 13.6/54.9 MiB 8.2 MB/s eta 0:00:06\n",
      "downloading -------- ----------------------- 13.8/54.9 MiB 6.6 MB/s eta 0:00:07\n",
      "downloading -------- ----------------------- 14.1/54.9 MiB 8.2 MB/s eta 0:00:06\n",
      "downloading -------- ----------------------- 14.5/54.9 MiB 6.6 MB/s eta 0:00:07\n",
      "downloading -------- ----------------------- 14.8/54.9 MiB 8.2 MB/s eta 0:00:06\n",
      "downloading -------- ----------------------- 15.2/54.9 MiB 8.2 MB/s eta 0:00:06\n",
      "downloading -------- ----------------------- 15.4/54.9 MiB 7.3 MB/s eta 0:00:06\n",
      "downloading --------- ---------------------- 15.7/54.9 MiB 7.3 MB/s eta 0:00:06\n",
      "downloading --------- ---------------------- 16.0/54.9 MiB 7.3 MB/s eta 0:00:06\n",
      "downloading --------- ---------------------- 16.4/54.9 MiB 8.2 MB/s eta 0:00:05\n",
      "downloading --------- --------------------- 16.9/54.9 MiB 11.0 MB/s eta 0:00:04\n",
      "downloading ---------- --------------------- 17.2/54.9 MiB 9.4 MB/s eta 0:00:05\n",
      "downloading ---------- --------------------- 17.5/54.9 MiB 8.2 MB/s eta 0:00:05\n",
      "downloading ---------- -------------------- 17.9/54.9 MiB 10.9 MB/s eta 0:00:04\n",
      "downloading ---------- --------------------- 18.1/54.9 MiB 6.6 MB/s eta 0:00:06\n",
      "downloading ---------- --------------------- 18.4/54.9 MiB 7.3 MB/s eta 0:00:06\n",
      "downloading ---------- --------------------- 18.6/54.9 MiB 5.9 MB/s eta 0:00:07\n",
      "downloading ----------- -------------------- 19.1/54.9 MiB 8.2 MB/s eta 0:00:05\n",
      "downloading ---------- -------------------- 19.4/54.9 MiB 10.9 MB/s eta 0:00:04\n",
      "downloading ----------- ------------------- 19.9/54.9 MiB 10.9 MB/s eta 0:00:04\n",
      "downloading ----------- ------------------- 20.3/54.9 MiB 11.0 MB/s eta 0:00:04\n",
      "downloading ------------ ------------------- 20.8/54.9 MiB 9.4 MB/s eta 0:00:04\n",
      "downloading ------------ ------------------- 21.1/54.9 MiB 9.3 MB/s eta 0:00:04\n",
      "downloading ------------ ------------------- 21.5/54.9 MiB 9.3 MB/s eta 0:00:04\n",
      "downloading ------------ ------------------- 22.0/54.9 MiB 9.3 MB/s eta 0:00:04\n",
      "downloading ------------ ------------------ 22.5/54.9 MiB 11.0 MB/s eta 0:00:04\n",
      "downloading ------------ ------------------ 22.9/54.9 MiB 11.0 MB/s eta 0:00:04\n",
      "downloading ------------- ------------------ 23.3/54.9 MiB 9.4 MB/s eta 0:00:04\n",
      "downloading ------------- ----------------- 23.8/54.9 MiB 11.0 MB/s eta 0:00:03\n",
      "downloading ------------- ----------------- 24.1/54.9 MiB 11.0 MB/s eta 0:00:03\n",
      "downloading ------------- ----------------- 24.6/54.9 MiB 10.9 MB/s eta 0:00:03\n",
      "downloading -------------- ----------------- 24.8/54.9 MiB 9.3 MB/s eta 0:00:04\n",
      "downloading -------------- ----------------- 25.3/54.9 MiB 9.3 MB/s eta 0:00:04\n",
      "downloading -------------- ---------------- 25.9/54.9 MiB 13.1 MB/s eta 0:00:03\n",
      "downloading -------------- ---------------- 26.4/54.9 MiB 13.1 MB/s eta 0:00:03\n",
      "downloading --------------- --------------- 26.9/54.9 MiB 10.9 MB/s eta 0:00:03\n",
      "downloading --------------- --------------- 27.3/54.9 MiB 10.9 MB/s eta 0:00:03\n",
      "downloading --------------- --------------- 27.7/54.9 MiB 10.9 MB/s eta 0:00:03\n",
      "downloading ---------------- --------------- 28.1/54.9 MiB 9.3 MB/s eta 0:00:04\n",
      "downloading ---------------- --------------- 28.3/54.9 MiB 7.3 MB/s eta 0:00:04\n",
      "downloading ---------------- --------------- 28.3/54.9 MiB 5.4 MB/s eta 0:00:06\n",
      "downloading ---------------- --------------- 28.7/54.9 MiB 7.3 MB/s eta 0:00:04\n",
      "downloading ---------------- --------------- 29.1/54.9 MiB 5.5 MB/s eta 0:00:05\n",
      "downloading ----------------- -------------- 29.6/54.9 MiB 8.2 MB/s eta 0:00:04\n",
      "downloading ----------------- -------------- 30.0/54.9 MiB 9.4 MB/s eta 0:00:03\n",
      "downloading ----------------- -------------- 30.2/54.9 MiB 8.2 MB/s eta 0:00:04\n",
      "downloading ----------------- -------------- 30.6/54.9 MiB 7.3 MB/s eta 0:00:04\n",
      "downloading ----------------- ------------- 31.2/54.9 MiB 10.9 MB/s eta 0:00:03\n",
      "downloading ----------------- ------------- 31.4/54.9 MiB 10.9 MB/s eta 0:00:03\n",
      "downloading ------------------ ------------- 31.9/54.9 MiB 9.3 MB/s eta 0:00:03\n",
      "downloading ------------------ ------------- 32.3/54.9 MiB 9.3 MB/s eta 0:00:03\n",
      "downloading ------------------ ------------ 32.6/54.9 MiB 13.1 MB/s eta 0:00:02\n",
      "downloading ------------------- ------------ 33.1/54.9 MiB 9.4 MB/s eta 0:00:03\n",
      "downloading ------------------ ------------ 33.6/54.9 MiB 10.9 MB/s eta 0:00:03\n",
      "downloading ------------------- ----------- 34.2/54.9 MiB 13.1 MB/s eta 0:00:02\n",
      "downloading ------------------- ----------- 34.6/54.9 MiB 13.1 MB/s eta 0:00:02\n",
      "downloading ------------------- ----------- 35.1/54.9 MiB 10.9 MB/s eta 0:00:02\n",
      "downloading -------------------- ---------- 35.6/54.9 MiB 13.1 MB/s eta 0:00:02\n",
      "downloading -------------------- ----------- 36.0/54.9 MiB 9.4 MB/s eta 0:00:03\n",
      "downloading --------------------- ---------- 36.4/54.9 MiB 9.4 MB/s eta 0:00:03\n",
      "downloading -------------------- ---------- 36.8/54.9 MiB 13.1 MB/s eta 0:00:02\n",
      "downloading --------------------- ---------- 37.3/54.9 MiB 9.4 MB/s eta 0:00:02\n",
      "downloading --------------------- ---------- 37.4/54.9 MiB 9.4 MB/s eta 0:00:02\n",
      "downloading --------------------- ---------- 37.4/54.9 MiB 9.4 MB/s eta 0:00:02\n",
      "downloading --------------------- ---------- 37.6/54.9 MiB 4.7 MB/s eta 0:00:04\n",
      "downloading ---------------------- --------- 38.0/54.9 MiB 5.0 MB/s eta 0:00:04\n",
      "downloading --------------------- --------- 38.5/54.9 MiB 11.0 MB/s eta 0:00:02\n",
      "downloading ---------------------- -------- 38.9/54.9 MiB 12.9 MB/s eta 0:00:02\n",
      "downloading ---------------------- -------- 39.5/54.9 MiB 13.1 MB/s eta 0:00:02\n",
      "downloading ----------------------- -------- 39.8/54.9 MiB 9.4 MB/s eta 0:00:02\n",
      "downloading ----------------------- -------- 40.2/54.9 MiB 9.3 MB/s eta 0:00:02\n",
      "downloading ----------------------- -------- 40.5/54.9 MiB 9.3 MB/s eta 0:00:02\n",
      "downloading ----------------------- ------- 41.1/54.9 MiB 10.9 MB/s eta 0:00:02\n",
      "downloading ----------------------- ------- 41.6/54.9 MiB 11.0 MB/s eta 0:00:02\n",
      "downloading ----------------------- ------- 41.8/54.9 MiB 10.9 MB/s eta 0:00:02\n",
      "downloading ----------------------- ------- 42.4/54.9 MiB 10.9 MB/s eta 0:00:02\n",
      "downloading ------------------------ ------- 42.7/54.9 MiB 9.4 MB/s eta 0:00:02\n",
      "downloading ------------------------- ------ 43.1/54.9 MiB 9.4 MB/s eta 0:00:02\n",
      "downloading ------------------------- ------ 43.5/54.9 MiB 9.4 MB/s eta 0:00:02\n",
      "downloading ------------------------- ------ 44.0/54.9 MiB 9.3 MB/s eta 0:00:02\n",
      "downloading ------------------------- ------ 44.4/54.9 MiB 9.3 MB/s eta 0:00:02\n",
      "downloading ------------------------- ----- 44.9/54.9 MiB 11.0 MB/s eta 0:00:01\n",
      "downloading -------------------------- ----- 45.2/54.9 MiB 9.4 MB/s eta 0:00:02\n",
      "downloading ------------------------- ----- 45.5/54.9 MiB 10.9 MB/s eta 0:00:01\n",
      "downloading -------------------------- ----- 45.9/54.9 MiB 7.3 MB/s eta 0:00:02\n",
      "downloading -------------------------- ----- 46.0/54.9 MiB 9.3 MB/s eta 0:00:01\n",
      "downloading -------------------------- ----- 46.0/54.9 MiB 9.3 MB/s eta 0:00:01\n",
      "downloading -------------------------- ----- 46.0/54.9 MiB 9.3 MB/s eta 0:00:01\n",
      "downloading --------------------------- ---- 46.5/54.9 MiB 5.0 MB/s eta 0:00:02\n",
      "downloading --------------------------- ---- 47.0/54.9 MiB 4.7 MB/s eta 0:00:02\n",
      "downloading --------------------------- ---- 47.3/54.9 MiB 9.4 MB/s eta 0:00:01\n",
      "downloading --------------------------- ---- 47.8/54.9 MiB 9.4 MB/s eta 0:00:01\n",
      "downloading --------------------------- --- 48.2/54.9 MiB 10.9 MB/s eta 0:00:01\n",
      "downloading ---------------------------- --- 48.4/54.9 MiB 8.2 MB/s eta 0:00:01\n",
      "downloading ---------------------------- --- 48.8/54.9 MiB 9.3 MB/s eta 0:00:01\n",
      "downloading ---------------------------- --- 49.2/54.9 MiB 9.3 MB/s eta 0:00:01\n",
      "downloading ---------------------------- --- 49.6/54.9 MiB 8.2 MB/s eta 0:00:01\n",
      "downloading ----------------------------- -- 49.9/54.9 MiB 8.2 MB/s eta 0:00:01\n",
      "downloading ----------------------------- -- 50.4/54.9 MiB 9.3 MB/s eta 0:00:01\n",
      "downloading ----------------------------- -- 50.8/54.9 MiB 7.3 MB/s eta 0:00:01\n",
      "downloading ---------------------------- -- 51.2/54.9 MiB 11.0 MB/s eta 0:00:01\n",
      "downloading ------------------------------ - 51.6/54.9 MiB 8.2 MB/s eta 0:00:01\n",
      "downloading ------------------------------ - 51.9/54.9 MiB 8.2 MB/s eta 0:00:01\n",
      "downloading ------------------------------ - 52.3/54.9 MiB 9.3 MB/s eta 0:00:01\n",
      "downloading ------------------------------ - 52.7/54.9 MiB 9.3 MB/s eta 0:00:01\n",
      "downloading ------------------------------ - 52.8/54.9 MiB 9.4 MB/s eta 0:00:01\n",
      "downloading -------------------------------  53.2/54.9 MiB 8.2 MB/s eta 0:00:01\n",
      "downloading -------------------------------  53.4/54.9 MiB 5.9 MB/s eta 0:00:01\n",
      "downloading -------------------------------  53.8/54.9 MiB 8.2 MB/s eta 0:00:01\n",
      "downloading ------------------------------  54.2/54.9 MiB 10.9 MB/s eta 0:00:01\n",
      "downloading ------------------------------  54.6/54.9 MiB 10.9 MB/s eta 0:00:01\n",
      "downloading -------------------------------- 54.9/54.9 MiB 9.4 MB/s eta 0:00:00\n",
      "Successfully downloaded rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth to c:\\Users\\Akshat\\Desktop\\Fire-and-Smoke-Detection-App\\RTMDet\n",
      "Successfully dumped rtmdet_tiny_8xb32-300e_coco.py to c:\\Users\\Akshat\\Desktop\\Fire-and-Smoke-Detection-App\\RTMDet\n"
     ]
    }
   ],
   "source": [
    "# # New cell to download configs\n",
    "# !mim download mmdet --config rtmdet_tiny_8xb32-300e_coco --dest ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "835c216d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training command is C:\\Users\\Akshat\\anaconda3\\envs\\mmdet_env\\python.exe c:\\users\\akshat\\anaconda3\\envs\\mmdet_env\\lib\\site-packages\\mmdet\\.mim\\tools\\train.py custom_rtmdet.py --launcher none. \n",
      "04/20 13:47:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: win32\n",
      "    Python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]\n",
      "    CUDA available: False\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1715166096\n",
      "    MSVC: Microsoft (R) C/C++ Optimizing Compiler Version 19.43.34810 for x64\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.6.0+cpu\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 201703\n",
      "  - MSVC 192930157\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2025.0.1-Product Build 20241031 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)\n",
      "  - OpenMP 2019\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - CPU capability usage: AVX2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, COMMIT_SHA=2236df1770800ffea5697b11b0bb0d910b2e59e1, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/pytorch/.ci/pytorch/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.6.0, USE_CUDA=0, USE_CUDNN=OFF, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 1715166096\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "04/20 13:47:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "base_lr = 0.004\n",
      "batch_size = 32\n",
      "checkpoint = 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth'\n",
      "custom_hooks = [\n",
      "    dict(\n",
      "        ema_type='ExpMomentumEMA',\n",
      "        momentum=0.0002,\n",
      "        priority=49,\n",
      "        type='EMAHook',\n",
      "        update_buffers=True),\n",
      "    dict(\n",
      "        switch_epoch=280,\n",
      "        switch_pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(crop_size=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='RandomCrop'),\n",
      "            dict(type='YOLOXHSVRandomAug'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='PipelineSwitchHook'),\n",
      "]\n",
      "data_root = 'data/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=10, max_keep_ckpts=3, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_scales = [\n",
      "    (\n",
      "        640,\n",
      "        640,\n",
      "    ),\n",
      "    (\n",
      "        320,\n",
      "        320,\n",
      "    ),\n",
      "    (\n",
      "        960,\n",
      "        960,\n",
      "    ),\n",
      "]\n",
      "interval = 10\n",
      "launcher = 'none'\n",
      "load_from = 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_tiny_8xb32-300e_coco/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 100\n",
      "metainfo = dict(\n",
      "    classes=(\n",
      "        'fire',\n",
      "        'smoke',\n",
      "    ), palette=[\n",
      "        (\n",
      "            220,\n",
      "            20,\n",
      "            60,\n",
      "        ),\n",
      "        (\n",
      "            119,\n",
      "            11,\n",
      "            32,\n",
      "        ),\n",
      "    ])\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        arch='P5',\n",
      "        channel_attention=True,\n",
      "        deepen_factor=0.167,\n",
      "        expand_ratio=0.5,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth',\n",
      "            prefix='backbone.',\n",
      "            type='Pretrained'),\n",
      "        norm_cfg=dict(type='SyncBN'),\n",
      "        type='CSPNeXt',\n",
      "        widen_factor=0.375),\n",
      "    bbox_head=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        anchor_generator=dict(\n",
      "            offset=0, strides=[\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ], type='MlvlPointGenerator'),\n",
      "        bbox_coder=dict(type='DistancePointBBoxCoder'),\n",
      "        exp_on_reg=False,\n",
      "        feat_channels=96,\n",
      "        in_channels=96,\n",
      "        loss_bbox=dict(loss_weight=2.0, type='GIoULoss'),\n",
      "        loss_cls=dict(\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0,\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True),\n",
      "        norm_cfg=dict(type='SyncBN'),\n",
      "        num_classes=2,\n",
      "        pred_kernel_size=1,\n",
      "        share_conv=True,\n",
      "        stacked_convs=2,\n",
      "        type='RTMDetSepBNHead',\n",
      "        with_objectness=False),\n",
      "    data_preprocessor=dict(\n",
      "        batch_augments=None,\n",
      "        bgr_to_rgb=False,\n",
      "        mean=[\n",
      "            103.53,\n",
      "            116.28,\n",
      "            123.675,\n",
      "        ],\n",
      "        std=[\n",
      "            57.375,\n",
      "            57.12,\n",
      "            58.395,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        act_cfg=dict(inplace=True, type='SiLU'),\n",
      "        expand_ratio=0.5,\n",
      "        in_channels=[\n",
      "            96,\n",
      "            192,\n",
      "            384,\n",
      "        ],\n",
      "        norm_cfg=dict(type='SyncBN'),\n",
      "        num_csp_blocks=1,\n",
      "        out_channels=96,\n",
      "        type='CSPNeXtPAFPN'),\n",
      "    test_cfg=dict(\n",
      "        max_per_img=300,\n",
      "        min_bbox_size=0,\n",
      "        nms=dict(iou_threshold=0.65, type='nms'),\n",
      "        nms_pre=30000,\n",
      "        score_thr=0.001),\n",
      "    train_cfg=dict(\n",
      "        allowed_border=-1,\n",
      "        assigner=dict(topk=13, type='DynamicSoftLabelAssigner'),\n",
      "        debug=False,\n",
      "        pos_weight=-1),\n",
      "    type='RTMDet')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.004, type='AdamW', weight_decay=0.05),\n",
      "    paramwise_cfg=dict(\n",
      "        bias_decay_mult=0, bypass_duplicate=True, norm_decay_mult=0),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1000, start_factor=1e-05,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        T_max=150,\n",
      "        begin=150,\n",
      "        by_epoch=True,\n",
      "        convert_to_iter_based=True,\n",
      "        end=300,\n",
      "        eta_min=0.0002,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "resume = False\n",
      "stage2_num_epochs = 20\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=32,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/'),\n",
      "        data_root='data/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'fire',\n",
      "                'smoke',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/annotations/instances_test.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    proposal_nums=(\n",
      "        100,\n",
      "        1,\n",
      "        10,\n",
      "    ),\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='Resize'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='Pad'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    dynamic_intervals=[\n",
      "        (\n",
      "            280,\n",
      "            1,\n",
      "        ),\n",
      "    ],\n",
      "    max_epochs=100,\n",
      "    type='EpochBasedTrainLoop',\n",
      "    val_interval=10)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=None,\n",
      "    batch_size=32,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='train/'),\n",
      "        data_root='data/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'fire',\n",
      "                'smoke',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                img_scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                max_cached_images=20,\n",
      "                pad_val=114.0,\n",
      "                random_pop=False,\n",
      "                type='CachedMosaic'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    1280,\n",
      "                    1280,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(crop_size=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='RandomCrop'),\n",
      "            dict(type='YOLOXHSVRandomAug'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(\n",
      "                img_scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                max_cached_images=10,\n",
      "                pad_val=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                ),\n",
      "                prob=0.5,\n",
      "                random_pop=False,\n",
      "                ratio_range=(\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                ),\n",
      "                type='CachedMixUp'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    pin_memory=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        img_scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        max_cached_images=20,\n",
      "        pad_val=114.0,\n",
      "        random_pop=False,\n",
      "        type='CachedMosaic'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            1280,\n",
      "            1280,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(crop_size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(type='YOLOXHSVRandomAug'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='Pad'),\n",
      "    dict(\n",
      "        img_scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        max_cached_images=10,\n",
      "        pad_val=(\n",
      "            114,\n",
      "            114,\n",
      "            114,\n",
      "        ),\n",
      "        prob=0.5,\n",
      "        random_pop=False,\n",
      "        ratio_range=(\n",
      "            1.0,\n",
      "            1.0,\n",
      "        ),\n",
      "        type='CachedMixUp'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "train_pipeline_stage2 = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            640,\n",
      "            640,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(crop_size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(type='YOLOXHSVRandomAug'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(pad_val=dict(img=(\n",
      "        114,\n",
      "        114,\n",
      "        114,\n",
      "    )), size=(\n",
      "        640,\n",
      "        640,\n",
      "    ), type='Pad'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "tta_model = dict(\n",
      "    tta_cfg=dict(max_per_img=100, nms=dict(iou_threshold=0.6, type='nms')),\n",
      "    type='DetTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ), type='Resize'),\n",
      "                dict(keep_ratio=True, scale=(\n",
      "                    320,\n",
      "                    320,\n",
      "                ), type='Resize'),\n",
      "                dict(keep_ratio=True, scale=(\n",
      "                    960,\n",
      "                    960,\n",
      "                ), type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(prob=1.0, type='RandomFlip'),\n",
      "                dict(prob=0.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    pad_val=dict(img=(\n",
      "                        114,\n",
      "                        114,\n",
      "                        114,\n",
      "                    )),\n",
      "                    size=(\n",
      "                        960,\n",
      "                        960,\n",
      "                    ),\n",
      "                    type='Pad'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\n",
      "            ],\n",
      "            [\n",
      "                dict(\n",
      "                    meta_keys=(\n",
      "                        'img_id',\n",
      "                        'img_path',\n",
      "                        'ori_shape',\n",
      "                        'img_shape',\n",
      "                        'scale_factor',\n",
      "                        'flip',\n",
      "                        'flip_direction',\n",
      "                    ),\n",
      "                    type='PackDetInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=32,\n",
      "    dataset=dict(\n",
      "        ann_file='annotations/instances_val.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val/'),\n",
      "        data_root='data/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'fire',\n",
      "                'smoke',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    220,\n",
      "                    20,\n",
      "                    60,\n",
      "                ),\n",
      "                (\n",
      "                    119,\n",
      "                    11,\n",
      "                    32,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                640,\n",
      "                640,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    114,\n",
      "                    114,\n",
      "                    114,\n",
      "                )),\n",
      "                size=(\n",
      "                    640,\n",
      "                    640,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='data/annotations/instances_val.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    proposal_nums=(\n",
      "        100,\n",
      "        1,\n",
      "        10,\n",
      "    ),\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs\\\\custom_rtmdet'\n",
      "\n",
      "04/20 13:47:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "04/20 13:47:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_load_checkpoint:\n",
      "(49          ) EMAHook                            \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(NORMAL      ) PipelineSwitchHook                 \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_save_checkpoint:\n",
      "(49          ) EMAHook                            \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(49          ) EMAHook                            \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.2.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.2.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.main_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.main_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.short_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.short_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.final_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.final_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.attention.fc.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.main_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.main_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.short_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.short_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.final_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.final_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.attention.fc.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.main_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.main_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.short_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.short_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.final_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.final_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.attention.fc.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv2.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv2.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.main_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.main_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.short_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.short_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.final_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.final_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.attention.fc.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.2.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.2.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.0.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.0.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.0.1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.0.1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.1.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.1.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.1.1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.1.1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.2.0.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.2.0.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.2.1.bn.weight:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.reg_convs.2.1.bn.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_cls.0.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_cls.1.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_cls.2.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_reg.0.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_reg.1.bias:weight_decay=0.0\n",
      "04/20 13:47:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_reg.2.bias:weight_decay=0.0\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "04/20 13:47:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load backbone. in model from: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_tiny_8xb32-300e_coco/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for bbox_head.rtm_cls.0.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 96, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_cls.0.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "size mismatch for bbox_head.rtm_cls.1.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 96, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_cls.1.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "size mismatch for bbox_head.rtm_cls.2.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 96, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_cls.2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
      "\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for bbox_head.rtm_cls.0.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 96, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_cls.0.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "size mismatch for bbox_head.rtm_cls.1.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 96, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_cls.1.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "size mismatch for bbox_head.rtm_cls.2.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 96, 1, 1]).\n",
      "size mismatch for bbox_head.rtm_cls.2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
      "\n",
      "04/20 13:47:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_tiny_8xb32-300e_coco/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth\n",
      "04/20 13:47:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "04/20 13:47:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "04/20 13:47:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to c:\\Users\\Akshat\\Desktop\\Fire-and-Smoke-Detection-App\\RTMDet\\work_dirs\\custom_rtmdet.\n",
      "04/20 13:56:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][ 50/240]  base_lr: 1.9623e-04 lr: 1.9623e-04  eta: 3 days, 1:22:14  time: 11.0286  data_time: 0.4727  loss: 2.4971  loss_cls: 1.7135  loss_bbox: 0.7835\n",
      "04/20 14:03:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][100/240]  base_lr: 3.9643e-04 lr: 3.9643e-04  eta: 2 days, 13:27:13  time: 7.4847  data_time: 0.0164  loss: 1.7239  loss_cls: 1.1249  loss_bbox: 0.5990\n",
      "04/20 14:09:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][150/240]  base_lr: 5.9663e-04 lr: 5.9663e-04  eta: 2 days, 9:05:54  time: 7.3427  data_time: 0.0251  loss: 1.2169  loss_cls: 0.7291  loss_bbox: 0.4878\n",
      "04/20 14:15:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][200/240]  base_lr: 7.9683e-04 lr: 7.9683e-04  eta: 2 days, 6:43:13  time: 7.2523  data_time: 0.0156  loss: 1.1259  loss_cls: 0.6503  loss_bbox: 0.4756\n",
      "04/20 14:20:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: custom_rtmdet_20250420_134732\n",
      "04/20 14:26:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][ 50/240]  base_lr: 1.1572e-03 lr: 1.1572e-03  eta: 2 days, 4:22:23  time: 7.2987  data_time: 0.0417  loss: 1.0694  loss_cls: 0.6031  loss_bbox: 0.4663\n",
      "04/20 14:32:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][100/240]  base_lr: 1.3574e-03 lr: 1.3574e-03  eta: 2 days, 3:42:52  time: 7.3849  data_time: 0.0189  loss: 1.0460  loss_cls: 0.5852  loss_bbox: 0.4608\n",
      "04/20 14:39:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][150/240]  base_lr: 1.5576e-03 lr: 1.5576e-03  eta: 2 days, 4:03:50  time: 8.4142  data_time: 0.0210  loss: 1.0519  loss_cls: 0.5947  loss_bbox: 0.4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshat\\anaconda3\\envs\\mmdet_env\\lib\\site-packages\\mmdet\\models\\layers\\se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "C:\\Users\\Akshat\\anaconda3\\envs\\mmdet_env\\lib\\site-packages\\mmdet\\models\\backbones\\csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "C:\\Users\\Akshat\\anaconda3\\envs\\mmdet_env\\lib\\site-packages\\torch\\functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3638.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "!mim train mmdet custom_rtmdet.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
